{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1: Importer la bibliothèque Gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Objectif** : Exécuter 100 actions aléatoires et afficher les observations et les récompenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espace d'actions : Discrete(2)\n",
      "Espace d'observations : Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "\n",
      "Exercice 1 : Exécution d'actions aléatoires\n",
      "Action : 0, Observation : [-0.03829468 -0.17155358  0.03780995  0.28324544], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.04172575  0.02300925  0.04347486  0.00272325], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.04126557 -0.17270836  0.04352933  0.30879986], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.04471973 -0.36842263  0.04970533  0.61488676], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.05208819 -0.17402914  0.06200306  0.338264  ], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.05556877 -0.36997607  0.06876834  0.64983684], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.06296829 -0.17587599  0.08176508  0.37957683], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.06648581  0.0179954   0.08935662  0.11375346], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.0661259   0.2117309   0.09163168 -0.14945449], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.06189128  0.4054294   0.08864259 -0.41188127], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.05378269  0.59919024  0.08040497 -0.67535466], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.04179889  0.4030485   0.06689788 -0.3584789 ], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.03373792  0.5971588   0.05972829 -0.62933975], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.02179474  0.7913986   0.0471415  -0.90263027], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.00596677  0.5956708   0.02908889 -0.5955103 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.00594664  0.79037386  0.01717869 -0.8788904 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 2.1754121e-02  9.8525822e-01 -3.9911919e-04 -1.1661235e+00], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.04145928  0.79014146 -0.02372159 -0.87356573], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.05726212  0.9855778  -0.0411929  -1.1736113 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.07697367  0.79101473 -0.06466513 -0.8941215 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.09279396  0.98695123 -0.08254756 -1.2064103 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.11253299  0.79298717 -0.10667577 -0.94069636], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.12839274  0.59945214 -0.1254897  -0.6833472 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.14038178  0.40627548 -0.13915664 -0.43265802], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.14850728  0.60306513 -0.1478098  -0.7657691 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.1605686   0.79987955 -0.16312517 -1.1010697 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.17656618  0.99672765 -0.18514657 -1.4401684 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.19650073  0.8043054  -0.21394995 -1.2105906 ], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.00344931  0.2112489  -0.03607408 -0.3462269 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.00077566  0.01665817 -0.04299862 -0.06513416], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.00110883  0.21236938 -0.0443013  -0.37106735], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.00535621  0.4080918  -0.05172265 -0.67738324], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01351805  0.6038928  -0.06527031 -0.98589164], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.02559591  0.40970284 -0.08498815 -0.7144028 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.03378996  0.60589206 -0.0992762  -1.032581  ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.0459078   0.8021843  -0.11992782 -1.3547088 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.06195149  0.9985898  -0.147022   -1.6823753 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.08192328  1.195077   -0.1806695  -2.0169952 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.10582483  1.3915566  -0.2210094  -2.359746  ], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.01536977  0.19826908  0.00832038 -0.33862817], Récompense : 1.0\n",
      "Action : 1, Observation : [-0.01140439  0.39327165  0.00154782 -0.62867576], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.00353895  0.19812813 -0.0110257  -0.33550575], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.00042361  0.00316482 -0.01773581 -0.04632004], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.00048691  0.19853655 -0.01866221 -0.34454557], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.00445764  0.39391893 -0.02555312 -0.6430545 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.01233601  0.19916229 -0.03841421 -0.3585267 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01631926  0.39480868 -0.04558475 -0.6630708 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.02421543  0.20034958 -0.05884616 -0.38508242], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.02822243  0.00611027 -0.06654781 -0.11151858], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.02834463  0.20211957 -0.06877819 -0.42443237], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.03238702  0.39814496 -0.07726683 -0.7379801 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.04034992  0.20417029 -0.09202643 -0.47058004], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.04443333  0.40046346 -0.10143804 -0.7907915 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.0524426   0.20686978 -0.11725386 -0.5316654 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.05657999  0.01357536 -0.12788717 -0.2781083 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.0568515   0.21026774 -0.13344933 -0.60823387], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.06105686  0.40697807 -0.14561401 -0.93979365], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.06919642  0.21408717 -0.16440989 -0.69617873], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.07347816  0.41106126 -0.17833346 -1.0357747 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.08169939  0.21870023 -0.19904895 -0.80396175], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.08607339  0.02678251 -0.2151282  -0.579904  ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.01875673 -0.20278591 -0.0116056   0.25815532], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01470101 -0.00750021 -0.00644249 -0.03816547], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.01455101 -0.20252919 -0.0072058   0.25247785], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01050043 -0.00730509 -0.00215624 -0.04246919], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01035432  0.18784772 -0.00300562 -0.33583164], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01411128  0.38301232 -0.00972226 -0.6294609 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.02177153  0.5782686  -0.02231148 -0.92518973], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.0333369   0.7736847  -0.04081527 -1.2247999 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.04881059  0.9693078  -0.06531127 -1.5299865 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.06819674  1.1651536  -0.095911   -1.8423169 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.09149982  0.9712118  -0.13275734 -1.5808958 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.11092405  1.1676408  -0.16437525 -1.9118627 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.13427687  1.3641094  -0.2026125  -2.2507024 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.16155906  1.5604819  -0.24762656 -2.598397  ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.01363726 -0.16612595  0.0006612   0.301534  ], Récompense : 1.0\n",
      "Action : 1, Observation : [0.01031474 0.02898656 0.00669188 0.00905967], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01089447  0.22401191  0.00687307 -0.2815044 ], Récompense : 1.0\n",
      "Action : 0, Observation : [0.01537471 0.0287926  0.00124298 0.01333832], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01595056  0.2238967   0.00150975 -0.27895218], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.0204285   0.02875324 -0.00406929  0.01420654], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.02100356 -0.16631012 -0.00378516  0.3056028 ], Récompense : 1.0\n",
      "Action : 1, Observation : [0.01767736 0.02886557 0.00232689 0.01172852], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.01825467 -0.16628967  0.00256146  0.3051447 ], Récompense : 1.0\n",
      "Action : 1, Observation : [0.01492888 0.02879568 0.00866436 0.0132707 ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.01550479 -0.16644944  0.00892977  0.3086747 ], Récompense : 1.0\n",
      "Action : 1, Observation : [0.0121758  0.02854414 0.01510327 0.01882129], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01274668  0.22344626  0.01547969 -0.26905838], Récompense : 1.0\n",
      "Action : 0, Observation : [0.01721561 0.02810687 0.01009852 0.02846647], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.01777775  0.22308256  0.01066785 -0.26101324], Récompense : 1.0\n",
      "Action : 0, Observation : [0.0222394  0.02780996 0.00544759 0.03501529], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.0227956   0.22285338  0.00614789 -0.2559439 ], Récompense : 1.0\n",
      "Action : 0, Observation : [0.02725266 0.02764418 0.00102902 0.03867181], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.02780555 -0.16749251  0.00180245  0.33167922], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.0244557  -0.36264008  0.00843604  0.62493   ], Récompense : 1.0\n",
      "Action : 0, Observation : [ 0.0172029  -0.5578788   0.02093464  0.9202578 ], Récompense : 1.0\n",
      "Action : 1, Observation : [ 0.00604532 -0.3630459   0.03933979  0.6342269 ], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.0012156  -0.5586939   0.05202433  0.9390347 ], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.01238948 -0.75447714  0.07080503  1.2476006 ], Récompense : 1.0\n",
      "Action : 0, Observation : [-0.02747902 -0.95043194  0.09575704  1.5615956 ], Récompense : 1.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Créer l'environnement CartPole\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "env.reset()\n",
    "\n",
    "# Afficher les espaces d'action et d'observation\n",
    "print(f\"Espace d'actions : {env.action_space}\")\n",
    "print(f\"Espace d'observations : {env.observation_space}\")\n",
    "\n",
    "# Exercice 1 : Exécution d'actions aléatoires\n",
    "print(\"\\nExercice 1 : Exécution d'actions aléatoires\")\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()  # Action aléatoire\n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "    print(f\"Action : {action}, Observation : {observation}, Récompense : {reward}\")\n",
    "    \n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : Gestion des observations et des récompenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Objectif** : Prendre une action et afficher l'observation, la récompense et l'état terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercice 2 : Gestion des observations et des récompenses\n",
      "Observation : [-0.01128535  0.16022788 -0.02699003 -0.3319721 ]\n",
      "Récompense : 1.0\n",
      "Terminé : False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExercice 2 : Gestion des observations et des récompenses\")\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, _ = env.reset()\n",
    "\n",
    "# Prendre une action et récupérer les valeurs retournées\n",
    "action = env.action_space.sample()  # Action aléatoire\n",
    "observation, reward, done, _, _ = env.step(action)\n",
    "\n",
    "print(f\"Observation : {observation}\")\n",
    "print(f\"Récompense : {reward}\")\n",
    "print(f\"Terminé : {done}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3 : Contrôle manuel de l'agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Objectif** : Contrôler manuellement l'agent en entrant des actions (0 ou 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de l'épisode ! Récompense totale : 13.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "env.reset()\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "while True:\n",
    "    action = int(input(\"Entrer une action (0 ou 1) : \"))  # Demander une action à l'utilisateur\n",
    "    \n",
    "    if action not in [0, 1]:  \n",
    "        print(\"Action invalide ! Veuillez entrer 0 ou 1.\")\n",
    "        continue\n",
    "\n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "    if done:\n",
    "        print(f\"Fin de l'épisode ! Récompense totale : {total_reward}\")\n",
    "        env.close()\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 4 : Évaluation d'une politique aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Objectif** : Évaluer la performance d'une politique aléatoire sur 25 épisodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durée moyenne avant la fin d'un épisode : 24.44\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "num_episodes = 25\n",
    "episode_durations = []\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    env.reset()\n",
    "    duration = 0\n",
    "\n",
    "    while True:\n",
    "        action = env.action_space.sample()  # Action aléatoire\n",
    "        _, _, done, _, _ = env.step(action)\n",
    "        duration += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    episode_durations.append(duration)\n",
    "\n",
    "# Calculer et afficher la durée moyenne avant la fin d'un épisode\n",
    "average_duration = np.mean(episode_durations)\n",
    "print(f\"Durée moyenne avant la fin d'un épisode : {average_duration}\")\n",
    "\n",
    "# Fermer l'environnement\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
